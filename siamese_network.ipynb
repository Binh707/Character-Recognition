{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPIZ2TlJJ/H5a9ccUhhAoem"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8CI0ciRWxaS","executionInfo":{"status":"ok","timestamp":1683036540061,"user_tz":-420,"elapsed":511300,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}},"outputId":"96aeef54-513f-4d6b-9768-10cc8221bd53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Connect to drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"]},{"cell_type":"code","source":["import cv2 as cv\n","import numpy as np\n","import skimage.measure\n","from pathlib import Path\n","import pandas as pd\n","import re\n","import torch\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from google.colab.patches import cv2_imshow\n","import torchvision.transforms.functional as fn\n","from sklearn.model_selection import train_test_split\n","import random\n","import torch.nn.functional as F"],"metadata":{"id":"RX4M3hHayZ0z","executionInfo":{"status":"ok","timestamp":1683036546778,"user_tz":-420,"elapsed":6721,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data_path = '/content/drive/MyDrive/Project/Interview/Nan_junior/Data/'\n","image_size = 50"],"metadata":{"id":"3H5fRoMfzvsG","executionInfo":{"status":"ok","timestamp":1683036546778,"user_tz":-420,"elapsed":4,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Load template"],"metadata":{"id":"zw3E294S0MJJ"}},{"cell_type":"code","source":["data_dir = Path(data_path + 'templates')\n","paths_train = list((data_dir).glob('*.png'))[0:]\n","\n","hero_names = []\n","hero_templates = []\n","\n","for path in paths_train:\n","\tx = re.search(r'[\\]][\\w\\.\\_]+Original', str(path))\n","\thero_name = re.sub(r'[0-9]','',x.group()[1:-9]).lower()\n","\thero_names.append(hero_name)\n","\n","\timg = cv.imread(str(path))\n","\timg = cv.resize(img, [image_size,image_size], interpolation = cv.INTER_AREA)\n","\thero_templates.append(img)\n","\n"],"metadata":{"id":"oImahVhyyjlZ","executionInfo":{"status":"ok","timestamp":1683036565598,"user_tz":-420,"elapsed":18823,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Data augmentation"],"metadata":{"id":"8HH4uzEd0Pao"}},{"cell_type":"code","source":["def padding(img):\n","  resized_img = cv.resize(img, [img.shape[0]-10,img.shape[1]-10], interpolation = cv.INTER_AREA)\n","  top, bottom, left, right = 5, 5, 5, 5\n","  padded_img = cv.copyMakeBorder(resized_img, top, bottom, left, right, cv.BORDER_CONSTANT, value=[0, 0, 0])\n","  return padded_img\n","\n","def crop_circle(img):\n","  # print(img)\n","  hh, ww = img.shape[:2]\n","  hc, wc = hh//2, ww//2\n","  radius = hh//2\n","\n","  mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n","  # mask2 = np.zeros_like(img)\n","  mask = cv.circle(mask, (hc,wc), radius, (255,255), -1)\n","  cropped_img = cv.bitwise_and(img, img, mask=mask)\n","  return cropped_img\n","\n","\n","\n","def reduce_resolution(img, scale_factor, iter):\n","  height, width, _ = img.shape\n","\n","  low_resolution_img = cv.resize(img, [width, height], interpolation = cv.INTER_LINEAR)\n","  for i in range(iter):\n","    low_resolution_img = cv.resize(low_resolution_img, [width//scale_factor, height//scale_factor], interpolation = cv.INTER_LINEAR)\n","    low_resolution_img = cv.resize(low_resolution_img, [width, height], interpolation = cv.INTER_LINEAR)\n","  return low_resolution_img\n","\n","def change_brightness(img, value=-40):\n","\thsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n","\th, s, v = cv.split(hsv)\n","\tv = cv.add(v,value)\n","\tv[v > 255] = 255\n","\tv[v < 0] = 0\n","\tfinal_hsv = cv.merge((h, s, v))\n","\timg = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n","\treturn img"],"metadata":{"id":"1Q6e6kJO1G9B","executionInfo":{"status":"ok","timestamp":1683036565598,"user_tz":-420,"elapsed":20,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["hero_dataset = []\n","\n","for i in range(len(hero_templates)):\n","  hero_images = []\n","  hero_images.append(crop_circle(hero_templates[i]))\n","\n","  hero_images.append(change_brightness(crop_circle(hero_templates[i])))\n","\n","  hero_images.append(crop_circle(reduce_resolution(hero_templates[i],4,3)))\n","\n","  hero_images.append(crop_circle(reduce_resolution(hero_templates[i],4,5)))\n","\n","  hero_images.append(crop_circle(reduce_resolution(hero_templates[i],5,5)))\n","\n","  hero_images.append(crop_circle(reduce_resolution(hero_templates[i],7,4)))\n","\n","  hero_images.append(change_brightness(crop_circle(reduce_resolution(hero_templates[i],4,3))))\n","\n","  hero_images.append(change_brightness(crop_circle(reduce_resolution(hero_templates[i],4,5))))\n","\n","  hero_images.append(change_brightness(crop_circle(reduce_resolution(hero_templates[i],5,5))))\n","\n","  hero_images.append(change_brightness(crop_circle(reduce_resolution(hero_templates[i],7,4))))\n","\n","  #####\n","  hero_dataset.append(hero_images)\n","\n"],"metadata":{"id":"55KhfpNf0IsB","executionInfo":{"status":"ok","timestamp":1683036565599,"user_tz":-420,"elapsed":20,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(len(hero_dataset))\n","print(len(hero_dataset[0]))\n","print(len(hero_dataset[1]))"],"metadata":{"id":"gXOKq_UfrQp4","executionInfo":{"status":"ok","timestamp":1683036565599,"user_tz":-420,"elapsed":19,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed477265-c005-4ca5-e6e9-aef1137e9ecd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["79\n","10\n","10\n"]}]},{"cell_type":"markdown","source":["# Custom dataset"],"metadata":{"id":"wfkQGKO_QDX9"}},{"cell_type":"code","source":["#preprocessing and loading the dataset\n","class SiameseDataset(Dataset):\n","    def __init__(self, training_data=None, setSize = 7110):\n","        # used to prepare the labels and images path\n","        self.train_data = training_data\n","        self.size = setSize\n","\n","    def __len__(self):\n","      return self.size # 10 * len(self.train_data)\n","\n","    def __getitem__(self,index):\n","      img1 = None\n","      img2 = None\n","      label = None\n","      \n","      if index % 2 == 0: #select them same character for both images\n","        character = random.choice([*range(len(self.train_data))])\n","        i1 = random.choice([*range(len(self.train_data[character]))])\n","        i2 = random.choice([*range(len(self.train_data[character]))])\n","\n","        while i1 == i2:\n","          i2 = random.choice([*range(len(self.train_data[character]))])\n","\n","        img1 = self.train_data[character][i1]\n","        img2 = self.train_data[character][i2]\n","        label = 1.0\n","      else:\n","        character1 = random.choice([*range(len(self.train_data))])\n","        character2 = random.choice([*range(len(self.train_data))])\n","\n","        while character1 == character2:\n","          character2 = random.choice([*range(len(self.train_data))])\n","        i1 = random.choice([*range(len(self.train_data[character1]))])\n","        i2 = random.choice([*range(len(self.train_data[character2]))])\n","        img1 = self.train_data[character1][i1]\n","        img2 = self.train_data[character1][i2]\n","        label = 0.0\n","\n","\n","      img1 = np.stack([img1[:,:,0], img1[:,:,1], img1[:,:,2]])\n","      img2 = np.stack([img2[:,:,0], img2[:,:,1], img2[:,:,2]])\n","\n","      img1 = torch.tensor(img1, dtype=torch.float32)\n","      img2 = torch.tensor(img2, dtype=torch.float32)\n","      label = torch.from_numpy(np.array([label], dtype=np.float32)) \n","\n","      # img1 = img1 / 255.0\n","      # img2 = img2 / 255.0\n","\n","      return img1, img2, label"],"metadata":{"id":"8e6h4aethdjZ","executionInfo":{"status":"ok","timestamp":1683036565600,"user_tz":-420,"elapsed":19,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(len(hero_dataset))\n","dataset = SiameseDataset(hero_dataset)\n","train_dataset, val_dataset = torch.utils.data.random_split(dataset,[0.8,0.2])\n","\n","\n","train_dataloader = DataLoader(train_dataset, shuffle = True, batch_size = 64)\n","val_dataloader = DataLoader(val_dataset, shuffle = True, batch_size = 64)\n","print(len(train_dataloader))\n","print(len(val_dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MMRd4gaVIPn","executionInfo":{"status":"ok","timestamp":1683036565600,"user_tz":-420,"elapsed":19,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}},"outputId":"c1187160-5f90-49e6-cd06-0b9436e6b252"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["79\n","89\n","23\n"]}]},{"cell_type":"code","source":["# img1, img2, l = dataset[0]\n","# img1[1, 60:68, 60:68]"],"metadata":{"id":"uxVOLOPCWWEv","executionInfo":{"status":"ok","timestamp":1683036565601,"user_tz":-420,"elapsed":18,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"JAAicL7PP5CV"}},{"cell_type":"code","source":["class SiameseNetwork(torch.nn.Module):\n","    def __init__(self):\n","        super(SiameseNetwork, self).__init__()\n","        # Setting up the Sequential of CNN Layers\n","        self.cnn = torch.nn.Sequential(\n","            torch.nn.Conv2d(3, 96, kernel_size=11, stride=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(3, stride=2),\n","            torch.nn.Dropout2d(p=0.3),\n","            \n","            torch.nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(3, stride=2),\n","            torch.nn.Dropout2d(p=0.3),\n","\n","            torch.nn.Conv2d(256, 384 , kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(3, stride=2),\n","            # torch.nn.Dropout2d(p=0.3),\n","        )\n","        # Defining the fully connected layers\n","        self.fc = torch.nn.Sequential(\n","            torch.nn.Linear(6144, 256),\n","            # torch.nn.ReLU(),\n","            # torch.nn.Dropout2d(p=0.5),\n","            \n","            # torch.nn.Linear(1024, 128),\n","            # torch.nn.ReLU(),\n","            # torch.nn.Linear(128,16)\n","            )\n","        \n","    def forward_once(self, x):\n","        # Forward pass \n","        output = self.cnn(x)\n","        output = output.view(output.size()[0], -1)\n","        output = self.fc(output)\n","        return output\n","\n","    def forward(self, input1, input2):\n","        # forward pass of input 1\n","        feat1 = self.forward_once(input1)\n","        # forward pass of input 2\n","        feat2 = self.forward_once(input2)\n","        return feat1, feat2"],"metadata":{"id":"lCNMQ6WpwPMu","executionInfo":{"status":"ok","timestamp":1683036565601,"user_tz":-420,"elapsed":17,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Loss function"],"metadata":{"id":"NvqBo3yNP8B-"}},{"cell_type":"code","source":["class ContrastiveLoss(torch.nn.Module):\n","    \"\"\"\n","    Contrastive loss function.\n","    \"\"\"\n","\n","    def __init__(self, margin = 3.0):\n","        super(ContrastiveLoss, self).__init__()\n","        self.margin = margin\n","\n","    def forward(self, x0, x1, y):\n","        # euclidian distance\n","        diff = x0 - x1   # (batch, embedd size)\n","        # print(\"diff:\", diff.shape)\n","\n","        dist_sq = torch.mean(torch.pow(diff, 2), 1)   # (batch, )\n","        # print(\"dist_sq:\", dist_sq.shape)\n","\n","        dist = torch.sqrt(dist_sq)\n","        # print(\"dist:\", dist.shape)\n","\n","        mdist = self.margin - dist\n","        # print(\"mdist:\", mdist.shape)\n","\n","        dist = torch.clamp(mdist, min=0.0)\n","        # print(\"new_dist:\", dist.shape)\n","        \n","        y = torch.squeeze(y)\n","        # print(y.shape)\n","        loss = torch.mean(y * dist_sq + (1 - y) * torch.pow(dist, 2))\n","        # loss = torch.sum(loss) / x0.size()[0]\n","        # print(\"loss:\", loss.shape)\n","        return loss"],"metadata":{"id":"38e6F8Ky4Kk_","executionInfo":{"status":"ok","timestamp":1683036565601,"user_tz":-420,"elapsed":17,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Config"],"metadata":{"id":"qjbRQPc2PBtd"}},{"cell_type":"code","source":["batch_size = 64\n","num_epoch = 10"],"metadata":{"id":"HU3K3UN2LN_Q","executionInfo":{"status":"ok","timestamp":1683036565601,"user_tz":-420,"elapsed":17,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"eRmpwCkMPBbN"}},{"cell_type":"code","source":["# Declare Siamese Network\n","net = SiameseNetwork().cuda()\n","# Decalre Loss Function\n","criterion = ContrastiveLoss()\n","# Declare Optimizer\n","optimizer = torch.optim.Adam(net.parameters(), lr=1e-5, weight_decay=0.0005)\n","\n","#train the model\n","def train():\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    train_loss_list = []\n","    valid_loss_list = []\n","    best_valid_loss = float('Inf')\n","    global_step = 0\n","    global_step_list = []\n","    valid_period = len(val_dataloader)\n","    # loss=[] \n","    # counter=[]\n","    # iteration_number = 0\n","    net.train()\n","    for epoch in range(1, num_epoch + 1):\n","        for i, data in enumerate(train_dataloader,0):\n","            img0, img1 , label = data\n","            img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n","            optimizer.zero_grad()\n","\n","            output1, output2 = net(img0, img1)\n","            loss_contrastive = criterion(output1, output2, label)\n","            loss_contrastive.backward()\n","            optimizer.step()  \n","            \n","            # print(loss_contrastive.item())\n","            train_loss += loss_contrastive.item()\n","            global_step += 1\n","\n","            if global_step % valid_period == 0:\n","              net.eval()\n","              with torch.no_grad():\n","                for _, data in enumerate(val_dataloader):\n","                  img0, img1 , label = data\n","                  img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n","                  output1, output2 = net(img0, img1)\n","                  loss_contrastive = criterion(output1, output2, label)\n","                  valid_loss += loss_contrastive.item()\n","\n","              train_loss = train_loss / valid_period\n","              valid_loss = valid_loss / valid_period\n","              train_loss_list.append(train_loss)\n","              valid_loss_list.append(valid_loss)\n","              global_step_list.append(global_step)\n","\n","              # Print sumary\n","              print('Epoch [{}/{}], global_step [{}/{}], train loss {:.4f}, valid loss {:.4f}'\\\n","                    .format(epoch, num_epoch, global_step, num_epoch * len(train_dataloader), train_loss, valid_loss))\n","              # Save check point if model is better\n","              if best_valid_loss > valid_loss:\n","                best_valid_loss = valid_loss\n","                torch.save(net.state_dict(), data_path + \"weights/model.pt\")\n","                \n","              train_loss, valid_loss = 0.0, 0.0\n","              net.train()\n","\n","        # print(\"Epoch {}\\n Current loss {}\\n\".format(epoch, loss_contrastive.item()))\n","        # iteration_number += 10\n","        # counter.append(iteration_number)\n","        # loss.append(loss_contrastive.item())\n","    # show_plot(counter, loss)   \n","    return net\n","\n","#set the device to cuda\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = train()\n","# torch.save(model.state_dict(), data_path + \"weights/model.pt\")\n","print(\"Training Finished\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TUvVRfr94S73","executionInfo":{"status":"ok","timestamp":1683036627986,"user_tz":-420,"elapsed":62401,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}},"outputId":"834f3041-cb15-4a61-eeee-6cfd6d2672a3"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], global_step [23/890], train loss 15.7359, valid loss 3.0470\n","Epoch [1/10], global_step [46/890], train loss 6.6836, valid loss 3.4824\n","Epoch [1/10], global_step [69/890], train loss 4.0181, valid loss 3.5375\n","Epoch [2/10], global_step [92/890], train loss 3.3881, valid loss 3.6453\n","Epoch [2/10], global_step [115/890], train loss 2.7773, valid loss 3.7310\n","Epoch [2/10], global_step [138/890], train loss 2.6211, valid loss 3.7973\n","Epoch [2/10], global_step [161/890], train loss 2.4875, valid loss 3.8239\n","Epoch [3/10], global_step [184/890], train loss 2.4745, valid loss 3.7891\n","Epoch [3/10], global_step [207/890], train loss 2.4808, valid loss 3.8192\n","Epoch [3/10], global_step [230/890], train loss 2.3972, valid loss 3.8715\n","Epoch [3/10], global_step [253/890], train loss 2.4015, valid loss 3.9386\n","Epoch [4/10], global_step [276/890], train loss 2.4240, valid loss 3.8931\n","Epoch [4/10], global_step [299/890], train loss 2.3464, valid loss 3.9655\n","Epoch [4/10], global_step [322/890], train loss 2.4534, valid loss 3.9746\n","Epoch [4/10], global_step [345/890], train loss 2.3435, valid loss 3.8946\n","Epoch [5/10], global_step [368/890], train loss 2.4276, valid loss 3.8588\n","Epoch [5/10], global_step [391/890], train loss 2.3871, valid loss 3.9051\n","Epoch [5/10], global_step [414/890], train loss 2.3747, valid loss 3.9352\n","Epoch [5/10], global_step [437/890], train loss 2.3972, valid loss 3.9021\n","Epoch [6/10], global_step [460/890], train loss 2.4388, valid loss 3.8883\n","Epoch [6/10], global_step [483/890], train loss 2.3877, valid loss 3.8825\n","Epoch [6/10], global_step [506/890], train loss 2.4232, valid loss 3.9859\n","Epoch [6/10], global_step [529/890], train loss 2.3895, valid loss 3.9162\n","Epoch [7/10], global_step [552/890], train loss 2.3376, valid loss 3.9217\n","Epoch [7/10], global_step [575/890], train loss 2.4391, valid loss 3.9398\n","Epoch [7/10], global_step [598/890], train loss 2.3608, valid loss 3.9130\n","Epoch [7/10], global_step [621/890], train loss 2.3740, valid loss 3.9195\n","Epoch [8/10], global_step [644/890], train loss 2.3802, valid loss 4.0406\n","Epoch [8/10], global_step [667/890], train loss 2.3697, valid loss 3.9675\n","Epoch [8/10], global_step [690/890], train loss 2.4405, valid loss 3.8969\n","Epoch [9/10], global_step [713/890], train loss 2.4322, valid loss 3.8715\n","Epoch [9/10], global_step [736/890], train loss 2.3337, valid loss 3.8930\n","Epoch [9/10], global_step [759/890], train loss 2.4217, valid loss 3.9352\n","Epoch [9/10], global_step [782/890], train loss 2.4227, valid loss 3.9067\n","Epoch [10/10], global_step [805/890], train loss 2.3511, valid loss 3.8846\n","Epoch [10/10], global_step [828/890], train loss 2.3626, valid loss 3.9346\n","Epoch [10/10], global_step [851/890], train loss 2.3789, valid loss 3.9445\n","Epoch [10/10], global_step [874/890], train loss 2.3749, valid loss 3.8499\n","Training Finished\n"]}]},{"cell_type":"markdown","source":["# Test"],"metadata":{"id":"Lp2aSNbnUaf9"}},{"cell_type":"code","source":["def generate_test_image_pairs(images_dataset, labels_dataset, image):\n","   \n","    pair_images = []\n","    pair_labels = []\n","\n","    for i, hero in enumerate(images_dataset):\n","      r = random.choice([*range(len(hero))])\n","      test_image = hero[r]\n","      pair_images.append((image, test_image))\n","      pair_labels.append(labels_dataset[i])\n","    return np.array(pair_images), np.array(pair_labels)\n","\n","\n","def process_test_image(img):\n","  hh, ww = img.shape[0:2]\n","  crop = img[0 : img.shape[0], 0 : ww//2]\n","  crop = cv.bilateralFilter(crop, 11, 75, 75)\n","\n","  gray_img = cv.cvtColor(crop, cv.COLOR_BGR2GRAY)\n","  circles_img = cv.HoughCircles(gray_img,  cv.HOUGH_GRADIENT,1.0, ww,\n","                              param1=50, param2=10, minRadius=hh//5, maxRadius=hh//2+5)\n","  if circles_img is not None:\n","    circles_img = np.uint16(np.around(circles_img))\n","    for i in circles_img[0,:]:\n","      # Crop square of character's avatar\n","      r = i[2]\n","      if i[0] <= r:\n","        left = 0\n","      else:\n","        left = i[0]-r\n","      right = i[0] + r\n","\n","      if i[1] <= r:\n","        top = 0\n","      else:\n","        top = i[1]-r\n","      bottom = i[1] + r\n","\n","      crop = img[top:bottom, left:right]\n","      # crop = cv.detailEnhance(crop, sigma_s=10, sigma_r=0.15)\n","      # kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n","      # crop = cv.filter2D(crop, -1, kernel)\n","      \n","      # Crop circle and convert to size 128x128\n","      square_hh, square_ww = crop.shape[:2]\n","      square_hc, square_wc = square_hh//2, square_hh//2\n","      radius = square_hh//2\n","      \n","      mask = np.zeros(crop.shape[:2], dtype=\"uint8\")\n","      mask = cv.circle(mask, (square_hc, square_wc), radius, (255,255), -1)\n","      cropped_img = cv.bitwise_and(crop, crop, mask=mask)\n","      cropped_img = cv.resize(cropped_img, [image_size,image_size], interpolation = cv.INTER_CUBIC)\n","    return cropped_img\n","    \n","  else:\n","    crop = img[0 : img.shape[0], 0 : ww//3]\n","    cropped_img = cv.resize(crop, [image_size,image_size], interpolation = cv.INTER_CUBIC)\n","    return cropped_img"],"metadata":{"id":"vIHPO0gHRams","executionInfo":{"status":"ok","timestamp":1683036627987,"user_tz":-420,"elapsed":13,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["data_dir = Path(data_path + 'test_images')\n","paths_train = list((data_dir).glob('*.jpg'))[0:]\n","\n","test_images = []\n","test_labels = []\n","\n","with open(data_path + 'test.txt','r') as f:\n","  test_samples = f.readlines()\n","\n","test_data_path = data_path + 'test_images/'\n","\n","for sample in test_samples:\n","  file_name, label = sample.split('\\t')\n","  label = re.sub(r'[0-9]','',label).lower()\n","  test_labels.append(label.strip('\\n'))\n","  \n","  # print(file_name)\n","  img = cv.imread(test_data_path + file_name)\n","  test_images.append(process_test_image(img))\n","  \n","print(len(test_images))"],"metadata":{"id":"XirkcKbDcujW","executionInfo":{"status":"ok","timestamp":1683036653614,"user_tz":-420,"elapsed":25639,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"53e00d01-f07b-4340-eae1-a24423e332c0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["98\n"]}]},{"cell_type":"code","source":["#preprocessing and loading the dataset\n","class TestDataset(Dataset):\n","    def __init__(self, training_data=None, testing_data = None):\n","        # used to prepare the labels and images path\n","        self.train_data = training_data\n","        self.test_data = testing_data\n","\n","    def __len__(self):\n","      return len(self.train_data) * len(self.test_data)\n","\n","    def __getitem__(self,index):\n","      test_index = index // len(self.train_data)\n","      train_index = index % len(self.train_data)\n","      img1 = self.test_data[test_index]\n","\n","      r = random.choice([*range(len(self.train_data[train_index]))])\n","      img2 = self.train_data[train_index][r]\n","\n","      img1 = np.stack([img1[:,:,0], img1[:,:,1], img1[:,:,2]])\n","      img2 = np.stack([img2[:,:,0], img2[:,:,1], img2[:,:,2]])\n","\n","      img1 = torch.tensor(img1, dtype=torch.float32)\n","      img2 = torch.tensor(img2, dtype=torch.float32)\n","\n","      # img1 = img1 / 255.0\n","      # img2 = img2 / 255.0\n","\n","      return img1, img2"],"metadata":{"id":"u1XRwd9HlQgU","executionInfo":{"status":"ok","timestamp":1683036653614,"user_tz":-420,"elapsed":16,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["test_dataset = TestDataset(hero_dataset, test_images)\n","test_dataloader = DataLoader(test_dataset, shuffle = False, num_workers = 8, batch_size = len(hero_dataset))\n","print(len(test_dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GCYOF6RWs2n0","executionInfo":{"status":"ok","timestamp":1683036653615,"user_tz":-420,"elapsed":17,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}},"outputId":"fc8f12ea-3744-4458-d5b5-7f60c9815ec3"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["98\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["acc = 0\n","\n","# model = SiameseNetwork()\n","# model.load_state_dict(torch.load(data_path + \"weights/model.pt\"))\n","model.cuda()\n","model.eval()\n","with torch.no_grad():\n","  for label_index, data in enumerate(test_dataloader):\n","    img0, img1 = data\n","    img0, img1 = img0.cuda(), img1.cuda()\n","    output1, output2 = model(img0, img1)\n","    euclidean_distance = F.pairwise_distance(output1, output2)\n","    predict_index = torch.argmin(euclidean_distance).item()\n","\n","    if test_labels[label_index] == hero_names[predict_index]:\n","      acc+=1\n","\n","print('Accuracy:', acc, '/', len(test_images))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zuynCBR4UaDV","executionInfo":{"status":"ok","timestamp":1683036655933,"user_tz":-420,"elapsed":2333,"user":{"displayName":"Binh Ho","userId":"03735509384067967466"}},"outputId":"9d39aa68-a8c5-4a1e-c708-db000944f7b9"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 80 / 98\n"]}]}]}